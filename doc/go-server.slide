Concurrent Server Architectures

Yasha Bubnov
Backend Engineer, Juno
ybubnov@gojuno.com

* Input Data

- Transfer Control Protocol.
- Clients with persisted connections.
- Multiple requests from a single connection.


* Sequential Server

- Create a server socket (listener).
- Accept a client connection.
- Handle requests.
- Close the connection.


* Sequential Server

.code src/1-server.go /^func main/,/^}/


* Concurrent Server

- Create a server socket (listener).
- Accept a client connection.
- Handle requests concurrently.
- Close the connection.

* Forking & Threading

- Create a server socket.
- Start accepting client connections.
- Create a process/thread to handle each new client.

* Preforking & Prethreading

- Create a server socket.
- Spawn N processes.
- Start accepting client connections.


* Preforking & Prethreading - Thundering Herd

When an incoming TCP connection is accepted, all waiting processes / threads are awaken.


* Preforking - Thundering Herd

- Mutual exclusion through file locking.
- Passing file descriptors from parent process to children processes.


* Prethreading - Thundering Herd

- Mutual exclusion though shared semaphore.


* Preforking & Prethreading in Go

If there is no solution to the problem then don't waste time worrying about it.

    func ForkExec(argv0 string, argv []string, attr *ProcAttr) (pid int, err error)
        Combination of fork and exec, careful to be thread safe.


* C10K Problem

It's time for web servers to handle ten thousand clients simultaneously, don't you think?
Dan Kegel, 1999

- Serve many clients with each thread, and use nonblocking I/O.
- Serve many clients with each thread, and use asynchronous I/O.
- Build the server code into the kernel (kttpd).


* Concurrent Server in Go

Serve each incoming connection in a standalone goroutine.
.code src/2-server.go /^func main/,/^}/


* Handle requests concurrently

.code src/2-server.go /^func serve/,/^}/

Handle each incoming request from a single connection in a standalone goroutine.
.code src/2-server.go /^func handle/,/^}/


* Trivial Client

.code src/3-client.go /^func main/,/^}/


* Testing

- One server with 256 MiB memory.
- One client connection with 10^6 requests.

Spawn a container with a limited amount of memory and no swap:

    docker run -m 256M --memory-swap 256M ...

Eventually OOM kills it:

    signal: killed


* Why?

- The minimum stack size in Go is 2 KiB:

.code src/4-stack.go /START OMIT/,/END OMIT/

- Math:

    2KiB * 10^6 ~ 2TB

* Worker Pool

.code src/5-server.go /START POOL OMIT/,/END POOL OMIT/


* Pre-goroutined Server

.code src/5-server.go /^func main/,/^}/


* Pre-goroutined Server
.code src/5-server.go /^func serve/,/^}/


* Painful Present

- HTTP server from `"net/http"` does not _allow_ to setup handlers limit.
- HTTP2 server from `"x/net/http2"` does not _implement_ handlers limit.


* Conclusion

Go is a _framework_ for writing high-performance servers, but use it wisely.
