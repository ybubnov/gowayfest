Concurrent Server Architectures

Yasha Bubnov
Backend Engineer, Juno
ybubnov@gojuno.com

* Initial data

- Transfer Control Protocol.
- Clients with persisted connections.
- Multiple requests from a single connection.


* C10K Problem

It's time for web servers to handle ten thousand clients simultaneously, don't you think?
Dan Kegel, 1999

- Serve many clients with each thread, and use nonblocking I/O.
- Serve many clients with each thread, and use asynchronous I/O.
- Build the server code into the kernel (khttpd).


* How to Serve Many Clients


* Sequential Server

- Create a server socket (listener).
- Accept a client connection.
- Handle requests.
- Close the connection.

: Where is a link to Stevens book?


* Sequential Server

.code src/1-server.go /^func main/,/^}/


* Concurrent Server

- Create a server socket (listener).
- Accept a client connection.
- Handle requests concurrently.
- Close the connection.

* Forking & Threading

- Create a server socket.
- Start accepting client connections.
- Create a process/thread to handle each new client.

: Where are the images of these?


* Pre-forking & Pre-threading

- Create a server socket.
- Spawn N processes.
- Start accepting client connections.

: Examples of real-word applications?


* Pre-forking & Pre-threading - Thundering Herd

When an incoming TCP connection is accepted, all waiting processes / threads are awaken.


* Pre-forking - Thundering Herd

- Mutual exclusion through file locking.
- Passing file descriptors from parent process to children processes.


* Pre-threading - Thundering Herd

- Mutual exclusion though shared semaphore.

: Graphics?


* Pre-forking & Pre-threading in Go

If there is no solution to the problem then don't waste time worrying about it.

    func ForkExec(argv0 string, argv []string, attr *ProcAttr) (pid int, err error)
        Combination of fork and exec, careful to be thread safe.


* Concurrent Server in Go

Serve each incoming connection in a standalone goroutine.
.code src/2-server.go /^func main/,/^}/


* Handle requests concurrently

.code src/2-server.go /^func serve/,/^}/

Handle each incoming request from a single connection in a standalone goroutine.
.code src/2-server.go /^func handle/,/^}/


* Trivial Client

.code src/3-client.go /^func main/,/^}/


* Testing

- One server with 256 MiB memory.
- One client connection with 10^6 requests.

Spawn a container with a limited amount of memory and no swap:

    docker run -m 256M --memory-swap 256M ...

Eventually OOM kills it:

    signal: killed


* Why?

- The minimum stack size in Go is 2 KiB:

.code src/4-stack.go /START OMIT/,/END OMIT/

- Math:

    2KiB * 10^6 ~ 2TB

* Worker Pool

.code src/5-server.go /START POOL OMIT/,/END POOL OMIT/


* Pre-goroutining Server

.code src/5-server.go /^func main/,/^}/


* Handling Connections

.code src/6-server.go /^func main/,/^}/


* Handling Requests

.code src/6-server.go /^func serve/,/^}/


* Painful Reality

- HTTP server from `"net/http"` does not _allow_ to setup handlers limit.
- HTTP2 server from `"x/net/http2"` does not _implement_ handlers limit.


* Non-blocking I/O vs. Asynchronous I/O.

Correct questions:
- Non-blocking vs. Blocking.
- Asynchronous vs. Synchronous.

    Blocking synchronous:       select, poll.
    Non-blocking synchronous:   select, poll, epoll.
    Non-blocking asynchronous:  aio_*.

: Benchmarks??
: Move this to the middle and explain each approach in details.


* Conclusion

Go is a _framework_ for writing high-performance servers, but use it wisely.
